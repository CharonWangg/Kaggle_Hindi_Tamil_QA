{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"PreTrained","provenance":[],"collapsed_sections":[],"mount_file_id":"1JTLTXIjYJBa6oAePJercFRYGlsxbSfNs","authorship_tag":"ABX9TyOQQNOHATOQNhZL4/Jy/PNw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__eNuzYPp-Ev","executionInfo":{"elapsed":12844,"status":"ok","timestamp":1636874184563,"user":{"displayName":"Xinyue Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicuncDU8Icen2R8DV3Zp8YKvgAaXknWiF6RfZq=s64","userId":"06186608546937139658"},"user_tz":300},"outputId":"1d0eebc9-d5e7-4d47-ad47-1f676406c46f"},"source":["!pip install transformers\n","!pip install sentencepiece\n","!pip install transformers[sentencepiece]"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 58.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 8.2 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 57.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 67.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.3\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.12.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.62.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.46)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.10.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.3.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.19.5)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.96)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (3.10.0.2)\n","Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[sentencepiece]) (3.6.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.1.0)\n"]}]},{"cell_type":"code","metadata":{"id":"eCHz8mblhn5v"},"source":["while(True):\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-0uz2tQMnpBo"},"source":["import pandas as pd\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from transformers import (AutoModel,AutoModelForMaskedLM, \n","                          AutoTokenizer, LineByLineTextDataset,\n","                          DataCollatorForLanguageModeling,\n","                          Trainer, TrainingArguments)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Gu6DwHMln1ne","outputId":"c86d32db-685a-4b7c-ef57-17fd2b94bd59"},"source":["train_data = pd.read_csv('/content/drive/MyDrive/Kaggle/Hindi/results/train.csv')\n","train_qa = pd.read_csv('/content/drive/MyDrive/Kaggle/Hindi/input/fusion_corpus.csv')\n","valid_data = pd.read_csv('/content/drive/MyDrive/Kaggle/Hindi/results/valid.csv')\n","\n","chaii = pd.read_csv('/content/drive/MyDrive/Kaggle/Hindi/input/train.csv')\n","chaii[\"text\"] = chaii[\"question\"].str.cat(chaii[\"context\"])\n","chaii = chaii[\"text\"]\n","\n","valid_data = pd.concat([valid_data,chaii],ignore_index=True)\n","train_qa = train_qa[~train_qa[[\"question\",\"answer_text\",\"answer_start\",\"question\"]].duplicated()]\n","#test_data = pd.read_csv('/content/drive/MyDrive/Kaggle/Hindi/input/test.csv')\n","train_qa[\"text\"] = train_qa[\"question\"].str.cat(train_qa[\"context\"])\n","train_qa = train_qa[\"text\"]\n","\n","train_data = pd.concat([train_data,train_qa.reset_index()],ignore_index=True)\n","train_data = train_data[\"text\"]\n","valid_data = valid_data[\"text\"]\n","print(train_data.head())\n","train_data = train_data.astype(\"str\").apply(lambda x: \" \".join(x.split()))\n","valid_data = valid_data.astype(\"str\").apply(lambda x: \" \".join(x.split()))\n","\n","text  = '\\n'.join(train_data.tolist())\n","valid = '\\n'.join(valid_data.tolist())\n","with open('train_text.txt','w') as f:\n","  f.write(text)\n","\n","with open(\"valid_text.txt\",\"w\") as f:\n","  f.write(valid)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["0    किसी उत्पाद अथवा सेवा को बेचने अथवा प्रवर्तित ...\n","1    नारंगी एक पारिभाषित तथा दैनिक जीवन में प्रयुक्...\n","2    नारान पाकिस्तान के उत्तरी भाग में ख़ैबर-पख़्तू...\n","3    निर्देशांक: 27°11′N 78°01′E / 27.18°N 78.02°E ...\n","4    यह नेशनल बास्केटबॉल असोसिएशन की पश्चिमी कांफ़्...\n","Name: text, dtype: object\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"referenced_widgets":["6cb143fb538d4f96844f06a1dd8956f7","82e06743e47d4d7ba85524cdc6f0bc67","4017e8d2baba4a0e88bcba29c3c85a9c","20edb0d5ff5043aa9b4a8724d2666573","9c98dd4d9f0d4c1883bf989af6996679"]},"id":"DRTjsk4Nn3zQ","outputId":"6dff2c0a-650d-4001-fd79-a4f58e4251d8"},"source":["model_name = \"deepset/xlm-roberta-large-squad2\"\n","model = AutoModelForMaskedLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.save_pretrained(\"/content/drive/MyDrive/Kaggle/Hindi/models/pretrained\");"],"execution_count":null,"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cb143fb538d4f96844f06a1dd8956f7","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/606 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82e06743e47d4d7ba85524cdc6f0bc67","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.09G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaForMaskedLM: ['qa_outputs.bias', 'qa_outputs.weight']\n","- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForMaskedLM were not initialized from the model checkpoint at deepset/xlm-roberta-large-squad2 and are newly initialized: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4017e8d2baba4a0e88bcba29c3c85a9c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/179 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20edb0d5ff5043aa9b4a8724d2666573","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c98dd4d9f0d4c1883bf989af6996679","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNWc3T2Gn7S1","outputId":"19d9daa8-28b5-4033-fe0a-5ca0c2fabb48"},"source":["train_dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"train_text.txt\", #mention train text file here\n","    block_size=256)\n","\n","valid_dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"valid_text.txt\", #mention valid text file here\n","    block_size=256)\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n","\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/Kaggle/Hindi/models/pretrained\", #select model path for checkpoint\n","    overwrite_output_dir=True,\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    evaluation_strategy= 'steps',\n","    learning_rate=2e-05,\n","    weight_decay=1e-2,\n","    warmup_ratio=0.1,\n","    save_total_limit=2,\n","    eval_steps=1000,\n","    save_steps=10000,\n","    metric_for_best_model='eval_loss',\n","    greater_is_better=False,\n","    load_best_model_at_end =True,\n","    prediction_loss_only=True,\n","    report_to = \"none\")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Creating features from dataset file at train_text.txt\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JqIFw5PHn9i8","executionInfo":{"status":"ok","timestamp":1636945071920,"user_tz":300,"elapsed":1875667,"user":{"displayName":"Xinyue Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicuncDU8Icen2R8DV3Zp8YKvgAaXknWiF6RfZq=s64","userId":"06186608546937139658"}},"outputId":"ea7979ec-dd50-41a6-f796-9e9debf9f497"},"source":["trainer.train()\n"],"execution_count":7,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running training *****\n","  Num examples = 344060\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 64512\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='62001' max='64512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [62001/64512 12:11:34 < 29:37, 1.41 it/s, Epoch 2.88/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>6.893600</td>\n","      <td>5.858554</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>4.075400</td>\n","      <td>3.432065</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>2.718300</td>\n","      <td>2.361115</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>2.222900</td>\n","      <td>1.884248</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>1.975700</td>\n","      <td>1.680615</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>1.832600</td>\n","      <td>1.569257</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>1.719400</td>\n","      <td>1.496449</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>1.642400</td>\n","      <td>1.435950</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>1.611300</td>\n","      <td>1.382296</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>1.566000</td>\n","      <td>1.344025</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>1.510200</td>\n","      <td>1.314543</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>1.472800</td>\n","      <td>1.296071</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>1.469600</td>\n","      <td>1.276504</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>1.443100</td>\n","      <td>1.255439</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>1.419500</td>\n","      <td>1.239481</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>1.398700</td>\n","      <td>1.219177</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>1.378900</td>\n","      <td>1.209088</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>1.374500</td>\n","      <td>1.194353</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>1.348900</td>\n","      <td>1.192766</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>1.351700</td>\n","      <td>1.180166</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>1.344100</td>\n","      <td>1.165521</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>1.300400</td>\n","      <td>1.151158</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>1.300400</td>\n","      <td>1.146180</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>1.287100</td>\n","      <td>1.133828</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>1.271500</td>\n","      <td>1.125879</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>1.262000</td>\n","      <td>1.114648</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>1.257100</td>\n","      <td>1.108929</td>\n","    </tr>\n","    <tr>\n","      <td>28000</td>\n","      <td>1.241500</td>\n","      <td>1.100737</td>\n","    </tr>\n","    <tr>\n","      <td>29000</td>\n","      <td>1.229000</td>\n","      <td>1.091954</td>\n","    </tr>\n","    <tr>\n","      <td>30000</td>\n","      <td>1.215800</td>\n","      <td>1.086355</td>\n","    </tr>\n","    <tr>\n","      <td>31000</td>\n","      <td>1.218900</td>\n","      <td>1.080418</td>\n","    </tr>\n","    <tr>\n","      <td>32000</td>\n","      <td>1.202300</td>\n","      <td>1.076119</td>\n","    </tr>\n","    <tr>\n","      <td>33000</td>\n","      <td>1.197000</td>\n","      <td>1.062034</td>\n","    </tr>\n","    <tr>\n","      <td>34000</td>\n","      <td>1.206400</td>\n","      <td>1.069410</td>\n","    </tr>\n","    <tr>\n","      <td>35000</td>\n","      <td>1.187600</td>\n","      <td>1.056738</td>\n","    </tr>\n","    <tr>\n","      <td>36000</td>\n","      <td>1.175300</td>\n","      <td>1.051623</td>\n","    </tr>\n","    <tr>\n","      <td>37000</td>\n","      <td>1.185100</td>\n","      <td>1.041032</td>\n","    </tr>\n","    <tr>\n","      <td>38000</td>\n","      <td>1.175400</td>\n","      <td>1.035027</td>\n","    </tr>\n","    <tr>\n","      <td>39000</td>\n","      <td>1.162200</td>\n","      <td>1.033370</td>\n","    </tr>\n","    <tr>\n","      <td>40000</td>\n","      <td>1.169100</td>\n","      <td>1.030694</td>\n","    </tr>\n","    <tr>\n","      <td>41000</td>\n","      <td>1.147500</td>\n","      <td>1.023889</td>\n","    </tr>\n","    <tr>\n","      <td>42000</td>\n","      <td>1.164600</td>\n","      <td>1.025242</td>\n","    </tr>\n","    <tr>\n","      <td>43000</td>\n","      <td>1.141000</td>\n","      <td>1.020998</td>\n","    </tr>\n","    <tr>\n","      <td>44000</td>\n","      <td>1.117700</td>\n","      <td>1.011977</td>\n","    </tr>\n","    <tr>\n","      <td>45000</td>\n","      <td>1.126600</td>\n","      <td>1.012698</td>\n","    </tr>\n","    <tr>\n","      <td>46000</td>\n","      <td>1.109100</td>\n","      <td>1.003572</td>\n","    </tr>\n","    <tr>\n","      <td>47000</td>\n","      <td>1.113400</td>\n","      <td>1.000103</td>\n","    </tr>\n","    <tr>\n","      <td>48000</td>\n","      <td>1.118000</td>\n","      <td>1.000588</td>\n","    </tr>\n","    <tr>\n","      <td>49000</td>\n","      <td>1.112600</td>\n","      <td>0.994682</td>\n","    </tr>\n","    <tr>\n","      <td>50000</td>\n","      <td>1.102600</td>\n","      <td>0.994149</td>\n","    </tr>\n","    <tr>\n","      <td>51000</td>\n","      <td>1.118000</td>\n","      <td>0.988522</td>\n","    </tr>\n","    <tr>\n","      <td>52000</td>\n","      <td>1.103400</td>\n","      <td>0.986419</td>\n","    </tr>\n","    <tr>\n","      <td>53000</td>\n","      <td>1.095700</td>\n","      <td>0.982955</td>\n","    </tr>\n","    <tr>\n","      <td>54000</td>\n","      <td>1.084200</td>\n","      <td>0.982138</td>\n","    </tr>\n","    <tr>\n","      <td>55000</td>\n","      <td>1.093400</td>\n","      <td>0.979190</td>\n","    </tr>\n","    <tr>\n","      <td>56000</td>\n","      <td>1.090100</td>\n","      <td>0.975778</td>\n","    </tr>\n","    <tr>\n","      <td>57000</td>\n","      <td>1.080900</td>\n","      <td>0.972582</td>\n","    </tr>\n","    <tr>\n","      <td>58000</td>\n","      <td>1.088300</td>\n","      <td>0.971797</td>\n","    </tr>\n","    <tr>\n","      <td>59000</td>\n","      <td>1.094700</td>\n","      <td>0.969479</td>\n","    </tr>\n","    <tr>\n","      <td>60000</td>\n","      <td>1.077700</td>\n","      <td>0.967805</td>\n","    </tr>\n","    <tr>\n","      <td>61000</td>\n","      <td>1.075100</td>\n","      <td>0.965149</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='852' max='3796' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 852/3796 01:22 < 04:46, 10.26 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-10000\n","Configuration saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-10000/config.json\n","Model weights saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-10000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-20000\n","Configuration saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-20000/config.json\n","Model weights saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-20000/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-3w_v1] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-30000\n","Configuration saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-30000/config.json\n","Model weights saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-30000/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-10000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-40000\n","Configuration saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-40000/config.json\n","Model weights saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-40000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-50000\n","Configuration saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-50000/config.json\n","Model weights saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-50000/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-30000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","Saving model checkpoint to /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-60000\n","Configuration saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-60000/config.json\n","Model weights saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-60000/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-30000] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='64512' max='64512' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [64512/64512 12:44:13, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>6.893600</td>\n","      <td>5.858554</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>4.075400</td>\n","      <td>3.432065</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>2.718300</td>\n","      <td>2.361115</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>2.222900</td>\n","      <td>1.884248</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>1.975700</td>\n","      <td>1.680615</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>1.832600</td>\n","      <td>1.569257</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>1.719400</td>\n","      <td>1.496449</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>1.642400</td>\n","      <td>1.435950</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>1.611300</td>\n","      <td>1.382296</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>1.566000</td>\n","      <td>1.344025</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>1.510200</td>\n","      <td>1.314543</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>1.472800</td>\n","      <td>1.296071</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>1.469600</td>\n","      <td>1.276504</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>1.443100</td>\n","      <td>1.255439</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>1.419500</td>\n","      <td>1.239481</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>1.398700</td>\n","      <td>1.219177</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>1.378900</td>\n","      <td>1.209088</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>1.374500</td>\n","      <td>1.194353</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>1.348900</td>\n","      <td>1.192766</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>1.351700</td>\n","      <td>1.180166</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>1.344100</td>\n","      <td>1.165521</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>1.300400</td>\n","      <td>1.151158</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>1.300400</td>\n","      <td>1.146180</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>1.287100</td>\n","      <td>1.133828</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>1.271500</td>\n","      <td>1.125879</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>1.262000</td>\n","      <td>1.114648</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>1.257100</td>\n","      <td>1.108929</td>\n","    </tr>\n","    <tr>\n","      <td>28000</td>\n","      <td>1.241500</td>\n","      <td>1.100737</td>\n","    </tr>\n","    <tr>\n","      <td>29000</td>\n","      <td>1.229000</td>\n","      <td>1.091954</td>\n","    </tr>\n","    <tr>\n","      <td>30000</td>\n","      <td>1.215800</td>\n","      <td>1.086355</td>\n","    </tr>\n","    <tr>\n","      <td>31000</td>\n","      <td>1.218900</td>\n","      <td>1.080418</td>\n","    </tr>\n","    <tr>\n","      <td>32000</td>\n","      <td>1.202300</td>\n","      <td>1.076119</td>\n","    </tr>\n","    <tr>\n","      <td>33000</td>\n","      <td>1.197000</td>\n","      <td>1.062034</td>\n","    </tr>\n","    <tr>\n","      <td>34000</td>\n","      <td>1.206400</td>\n","      <td>1.069410</td>\n","    </tr>\n","    <tr>\n","      <td>35000</td>\n","      <td>1.187600</td>\n","      <td>1.056738</td>\n","    </tr>\n","    <tr>\n","      <td>36000</td>\n","      <td>1.175300</td>\n","      <td>1.051623</td>\n","    </tr>\n","    <tr>\n","      <td>37000</td>\n","      <td>1.185100</td>\n","      <td>1.041032</td>\n","    </tr>\n","    <tr>\n","      <td>38000</td>\n","      <td>1.175400</td>\n","      <td>1.035027</td>\n","    </tr>\n","    <tr>\n","      <td>39000</td>\n","      <td>1.162200</td>\n","      <td>1.033370</td>\n","    </tr>\n","    <tr>\n","      <td>40000</td>\n","      <td>1.169100</td>\n","      <td>1.030694</td>\n","    </tr>\n","    <tr>\n","      <td>41000</td>\n","      <td>1.147500</td>\n","      <td>1.023889</td>\n","    </tr>\n","    <tr>\n","      <td>42000</td>\n","      <td>1.164600</td>\n","      <td>1.025242</td>\n","    </tr>\n","    <tr>\n","      <td>43000</td>\n","      <td>1.141000</td>\n","      <td>1.020998</td>\n","    </tr>\n","    <tr>\n","      <td>44000</td>\n","      <td>1.117700</td>\n","      <td>1.011977</td>\n","    </tr>\n","    <tr>\n","      <td>45000</td>\n","      <td>1.126600</td>\n","      <td>1.012698</td>\n","    </tr>\n","    <tr>\n","      <td>46000</td>\n","      <td>1.109100</td>\n","      <td>1.003572</td>\n","    </tr>\n","    <tr>\n","      <td>47000</td>\n","      <td>1.113400</td>\n","      <td>1.000103</td>\n","    </tr>\n","    <tr>\n","      <td>48000</td>\n","      <td>1.118000</td>\n","      <td>1.000588</td>\n","    </tr>\n","    <tr>\n","      <td>49000</td>\n","      <td>1.112600</td>\n","      <td>0.994682</td>\n","    </tr>\n","    <tr>\n","      <td>50000</td>\n","      <td>1.102600</td>\n","      <td>0.994149</td>\n","    </tr>\n","    <tr>\n","      <td>51000</td>\n","      <td>1.118000</td>\n","      <td>0.988522</td>\n","    </tr>\n","    <tr>\n","      <td>52000</td>\n","      <td>1.103400</td>\n","      <td>0.986419</td>\n","    </tr>\n","    <tr>\n","      <td>53000</td>\n","      <td>1.095700</td>\n","      <td>0.982955</td>\n","    </tr>\n","    <tr>\n","      <td>54000</td>\n","      <td>1.084200</td>\n","      <td>0.982138</td>\n","    </tr>\n","    <tr>\n","      <td>55000</td>\n","      <td>1.093400</td>\n","      <td>0.979190</td>\n","    </tr>\n","    <tr>\n","      <td>56000</td>\n","      <td>1.090100</td>\n","      <td>0.975778</td>\n","    </tr>\n","    <tr>\n","      <td>57000</td>\n","      <td>1.080900</td>\n","      <td>0.972582</td>\n","    </tr>\n","    <tr>\n","      <td>58000</td>\n","      <td>1.088300</td>\n","      <td>0.971797</td>\n","    </tr>\n","    <tr>\n","      <td>59000</td>\n","      <td>1.094700</td>\n","      <td>0.969479</td>\n","    </tr>\n","    <tr>\n","      <td>60000</td>\n","      <td>1.077700</td>\n","      <td>0.967805</td>\n","    </tr>\n","    <tr>\n","      <td>61000</td>\n","      <td>1.075100</td>\n","      <td>0.965149</td>\n","    </tr>\n","    <tr>\n","      <td>62000</td>\n","      <td>1.064800</td>\n","      <td>0.964424</td>\n","    </tr>\n","    <tr>\n","      <td>63000</td>\n","      <td>1.083700</td>\n","      <td>0.965060</td>\n","    </tr>\n","    <tr>\n","      <td>64000</td>\n","      <td>1.090400</td>\n","      <td>0.961954</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 60735\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-60000 (score: 0.9678046703338623).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=64512, training_loss=1.5020002882395471, metrics={'train_runtime': 45854.0176, 'train_samples_per_second': 22.51, 'train_steps_per_second': 1.407, 'total_flos': 4.8130592401093594e+17, 'train_loss': 1.5020002882395471, 'epoch': 3.0})"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPdXlZ0-rToN","executionInfo":{"elapsed":9520,"status":"ok","timestamp":1636751092848,"user":{"displayName":"Xinyue Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicuncDU8Icen2R8DV3Zp8YKvgAaXknWiF6RfZq=s64","userId":"06186608546937139658"},"user_tz":300},"outputId":"1ae801a8-42c1-4b55-ec8b-a44e6420b789"},"source":["trainer.save_model(f\"/content/drive/MyDrive/Kaggle/Hindi/models/pretrained_small_xlm\")"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to /content/drive/MyDrive/Kaggle/Hindi/models/pretrained_small_xlm\n","Configuration saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained_small_xlm/config.json\n","Model weights saved in /content/drive/MyDrive/Kaggle/Hindi/models/pretrained_small_xlm/pytorch_model.bin\n"]}]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","headers":[["content-type","application/javascript"]],"ok":true,"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":93},"id":"5hMOmiC9r3cz","executionInfo":{"elapsed":8339,"status":"ok","timestamp":1636869753674,"user":{"displayName":"Xinyue Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicuncDU8Icen2R8DV3Zp8YKvgAaXknWiF6RfZq=s64","userId":"06186608546937139658"},"user_tz":300},"outputId":"06d4fb74-5928-4ffe-82a8-b9579aed8820"},"source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","\n","\n","# Then move kaggle.json into the folder where the API expects to find it.\n","!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"],"execution_count":null,"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-6706eade-f95b-4349-95a1-cb417ec832f2\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6706eade-f95b-4349-95a1-cb417ec832f2\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving kaggle.json to kaggle.json\n","User uploaded file \"kaggle.json\" with length 67 bytes\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7FgTnzAsBxs","executionInfo":{"elapsed":102453,"status":"ok","timestamp":1636870918684,"user":{"displayName":"Xinyue Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicuncDU8Icen2R8DV3Zp8YKvgAaXknWiF6RfZq=s64","userId":"06186608546937139658"},"user_tz":300},"outputId":"74ec21e9-954e-4ecb-9096-a41484e35369"},"source":["!kaggle datasets create -p /content/drive/MyDrive/Kaggle/Hindi/models/v6"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Starting upload for file fold-0.bin\n","Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n","100% 2.09G/2.09G [00:19<00:00, 115MB/s]\n","Upload successful: fold-0.bin (2GB)\n","Starting upload for file fold-1.bin\n","100% 2.09G/2.09G [00:19<00:00, 115MB/s]\n","Upload successful: fold-1.bin (2GB)\n","Starting upload for file fold-2.bin\n","100% 2.09G/2.09G [00:19<00:00, 115MB/s]\n","Upload successful: fold-2.bin (2GB)\n","Starting upload for file fold-3.bin\n","100% 2.09G/2.09G [00:19<00:00, 116MB/s]\n","Upload successful: fold-3.bin (2GB)\n","Starting upload for file fold-4.bin\n","100% 2.09G/2.09G [00:19<00:00, 115MB/s]\n","Upload successful: fold-4.bin (2GB)\n","Your private Dataset is being created. Please check progress at https://www.kaggle.com/charonwangg/self-hindi-v6\n"]}]},{"cell_type":"code","metadata":{"id":"PAoDvBzxvSYZ"},"source":[""],"execution_count":null,"outputs":[]}]}