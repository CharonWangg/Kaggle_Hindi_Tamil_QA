{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMthqJHgUu9j3odDfAJ3R+j"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"G02qMU2vvvO6"},"source":["# Baseline Solution v0.0.1"]},{"cell_type":"code","metadata":{"id":"suyspsUHR-CN"},"source":["# # magic\n","i = []\n","while(True):\n","  i.append(\"1\"*100000000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6YBw6EVLBYnI"},"source":["# Packages"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","headers":[["content-type","application/javascript"]],"ok":true,"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":93},"id":"Peb3IAm1lLnm","executionInfo":{"elapsed":4969,"status":"ok","timestamp":1636678742806,"user":{"displayName":"Xinyue Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicuncDU8Icen2R8DV3Zp8YKvgAaXknWiF6RfZq=s64","userId":"06186608546937139658"},"user_tz":300},"outputId":"dd546b11-727a-4181-cb4c-d6d568352ac5"},"source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","\n","\n","# Then move kaggle.json into the folder where the API expects to find it.\n","!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"],"execution_count":null,"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-c9326a4b-bd2a-4782-9100-bad1efe8eef6\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c9326a4b-bd2a-4782-9100-bad1efe8eef6\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving kaggle.json to kaggle.json\n","User uploaded file \"kaggle.json\" with length 67 bytes\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DA405zVqkyny","executionInfo":{"elapsed":17534,"status":"ok","timestamp":1636678808297,"user":{"displayName":"Xinyue Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicuncDU8Icen2R8DV3Zp8YKvgAaXknWiF6RfZq=s64","userId":"06186608546937139658"},"user_tz":300},"outputId":"572a7c9a-2c75-44f0-d71f-d66ce01d868f"},"source":["!kaggle datasets download -d bminixhofer/roberta-transferred-to-hindi-tamil-with-wechsel"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading roberta-transferred-to-hindi-tamil-with-wechsel.zip to /content\n","100% 2.31G/2.31G [00:16<00:00, 135MB/s]\n","100% 2.31G/2.31G [00:16<00:00, 149MB/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmO8y5FtlV6t","executionInfo":{"elapsed":28667,"status":"ok","timestamp":1636678836961,"user":{"displayName":"Xinyue Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicuncDU8Icen2R8DV3Zp8YKvgAaXknWiF6RfZq=s64","userId":"06186608546937139658"},"user_tz":300},"outputId":"dc8506d9-80c1-4063-fe27-1b536c231e4f"},"source":["!unzip roberta-transferred-to-hindi-tamil-with-wechsel"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  roberta-transferred-to-hindi-tamil-with-wechsel.zip\n","  inflating: roberta-large-wechsel-hindi/config.json  \n","  inflating: roberta-large-wechsel-hindi/pytorch_model.bin  \n","  inflating: roberta-large-wechsel-hindi/special_tokens_map.json  \n","  inflating: roberta-large-wechsel-hindi/tokenizer.json  \n","  inflating: roberta-large-wechsel-hindi/tokenizer_config.json  \n","  inflating: roberta-large-wechsel-hindi/training_args.bin  \n","  inflating: roberta-large-wechsel-hindi/vocab.txt  \n","  inflating: roberta-large-wechsel-tamil/config.json  \n","  inflating: roberta-large-wechsel-tamil/pytorch_model.bin  \n","  inflating: roberta-large-wechsel-tamil/special_tokens_map.json  \n","  inflating: roberta-large-wechsel-tamil/tokenizer.json  \n","  inflating: roberta-large-wechsel-tamil/tokenizer_config.json  \n","  inflating: roberta-large-wechsel-tamil/training_args.bin  \n","  inflating: roberta-large-wechsel-tamil/vocab.txt  \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nGlVkYy-Qa4d","executionInfo":{"elapsed":164,"status":"ok","timestamp":1636767268016,"user":{"displayName":"Xinyue Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicuncDU8Icen2R8DV3Zp8YKvgAaXknWiF6RfZq=s64","userId":"06186608546937139658"},"user_tz":300},"outputId":"22437aca-6f3d-45d8-8338-d3e4f950dd52"},"source":["%%writefile setup.sh\n","\n","git clone https://github.com/NVIDIA/apex\n","cd apex\n","pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Writing setup.sh\n"]}]},{"cell_type":"code","metadata":{"id":"iBhdyTFrQe9-"},"source":["!sh setup.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IY8TkY1yNkkY"},"source":["!pip install sentencepiece\n","!pip install transformers[sentencepiece]\n","!pip install transformers\n","!pip install optuna\n","#!pip install pyngrok"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aRx_TdEa7_99"},"source":["# !unzip drive/MyDrive/Kaggle/Hindi/checkpoints/5foldsroberta.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g74ZAEZCI56l","executionInfo":{"status":"ok","timestamp":1636998558114,"user_tz":300,"elapsed":22121,"user":{"displayName":"Xinyue Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicuncDU8Icen2R8DV3Zp8YKvgAaXknWiF6RfZq=s64","userId":"06186608546937139658"}},"outputId":"f569a325-2733-4b95-a3e6-77185ddf6a9f"},"source":["%pdb on\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.utils as utils\n","from transformers import AutoModel,AutoConfig,AutoTokenizer,logging\n","import transformers\n","from sklearn.model_selection import train_test_split\n","from torch.utils.tensorboard import SummaryWriter\n","import os\n","import re\n","import random\n","from tqdm import tqdm\n","import optuna\n","from optuna.samplers import TPESampler\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning)                                     \n","logging.set_verbosity_warning()\n","logging.set_verbosity_error()\n","try:\n","    from apex import amp\n","    APEX = True\n","except:\n","    APEX = False"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Automatic pdb calling has been turned ON\n"]}]},{"cell_type":"code","metadata":{"id":"jwrUgNow3Vr8"},"source":["# %reload_ext tensorboard\n","# %tensorboard --logdir drive/MyDrive/Kaggle/Hindi/logs/train_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gsso8UkYXpdW"},"source":["# Data Base"]},{"cell_type":"code","metadata":{"id":"gNpYFdqKByES"},"source":["base = 'drive/MyDrive/Kaggle/Hindi/'\n","#train = pd.read_csv(base+\"input/simple_corpus.csv\")\n","#valid = train.loc[train[\"kfold\"]==1,:]\n","#train = train.loc[train[\"kfold\"]!=1,:]\n","#test = pd.read_csv(base+\"input/test.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u_rPT_gLeJbd"},"source":["# Config"]},{"cell_type":"code","metadata":{"id":"feTmlMXJeLA3"},"source":["class Config:\n","  # random\n","  seed = 2021\n","\n","  # preprocessing\n","  model_name = \"/content/drive/MyDrive/Kaggle/Hindi/models/pretrained/checkpoint-60000\"\n","  model_type = 'roberta'\n","\n","  # tokenize\n","  doc_stride = 135\n","  max_seq_len = 400\n","\n","  # model\n","  hidden_dropout_prob = 0.1\n","  initializer_range = 0.02\n","  hidden_size = 1024\n","  max_query_length=64\n","\n","  # train\n","  n_epochs = 2\n","  optimizer_mode = \"ChildTuning-F\"\n","  learning_rate = 2e-5\n","  down_specific = True\n","  down_lr = 3e-5\n","  epsilon = 1e-8\n","  correct_bias = True\n","  weight_decay = 1e-2\n","  LR_schedule = 'linear-warmup'\n","  warm_frac = 0.2\n","  log_steps = 100\n","  upload_steps = 100\n","  train_batch_size = 4\n","  valid_batch_size = 128\n","  acc_gradient_steps = 2\n","  valid_intervals = 500\n","  patience = 5\n","\n","\n","  # cuda \n","  device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","  fp16 = APEX\n","  fp16_opt_level = \"O1\"\n","\n","  # log\n","  train_loss_path = 'drive/MyDrive/Kaggle/Hindi/logs/train_loss'\n","  valid_loss_path = 'drive/MyDrive/Kaggle/Hindi/logs/valid_loss'\n","  best_loss = 1\n","  best_acc = 0\n","  fold = 0\n","  checkpoint = \"output/fold_0.bin\"\n","  \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2giHLM17Yx8T"},"source":["def fix_all_seeds(seed):\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JGeI3w78OuYm"},"source":["# Text Processing"]},{"cell_type":"markdown","metadata":{"id":"YLxs6Fs9Oz_c"},"source":["Text Preprocessing"]},{"cell_type":"code","metadata":{"id":"Tkv9m90ZOuHF"},"source":["def text_preprocess(df):\n","  df = df.copy()\n","  df[\"context\"] = df[\"context\"].apply(lambda x: \" \".join(x.split()))\n","  df['question'] = df['question'].apply(lambda x: \" \".join(x.split()))\n"," \n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"olIJoe1fbSaO"},"source":["# Tokenize"]},{"cell_type":"code","metadata":{"id":"k9-S4vTBbUmk"},"source":["def tokenize(tokenizer,df):  \n","  #text = \"[cls]\"+df[\"question\"]+\"[sep]\"+df[\"context\"]+\"[sep]\"\n","  tokens_info = tokenizer(df[\"question\"],df[\"context\"], \n","                         padding='max_length',\n","                         truncation=\"only_second\",\n","                         stride=Config.doc_stride,\n","                         max_length=Config.max_seq_len,\n","                         return_overflowing_tokens=True,\n","                         return_offsets_mapping=True,\n","                         )\n","  \n","  return tokens_info"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Psoh4dpHX0xH"},"source":["# Make Examples"]},{"cell_type":"code","metadata":{"id":"vx4T-9lRXzKB"},"source":["def make_examples(df):\n","  tokenizer = AutoTokenizer.from_pretrained(Config.model_name)\n","  examples = []\n","  df[\"question\"] = df[\"question\"].str.lstrip()\n","\n","  # train \n","  if \"answer_text\" in df.columns:\n","    for i in range(df.shape[0]):\n","      tokens_info = tokenize(tokenizer,df.iloc[i,:])\n","      for j in range(len(tokens_info[\"input_ids\"])):\n","        example = {}\n","        #example[\"id\"] = df[\"id\"].iloc[i]\n","        example[\"context\"] = df[\"context\"].iloc[i]\n","        example[\"question\"] = df[\"question\"].iloc[i]\n","        example[\"example_id\"] = df[\"id\"].iloc[i]\n","        example[\"input_ids\"] = tokens_info[\"input_ids\"][j]\n","        example[\"attention_mask\"] = tokens_info[\"attention_mask\"][j]\n","        example[\"offset_mapping\"] = tokens_info[\"offset_mapping\"][j]\n","        example[\"sequence_ids\"] = [0 if i == None else i for i in tokens_info.sequence_ids(j)]\n","\n","        cls_index = tokens_info[\"input_ids\"][j].index(tokenizer.cls_token_id)\n","        sequence_ids = tokens_info.sequence_ids(j)\n","\n","        sample_index = tokens_info[\"overflow_to_sample_mapping\"][j]\n","\n","        # if len([df[\"answer_start\"].iloc[i]) == 0:\n","        #   example[\"answer_start\"] = cls_index\n","        #   example[\"answer_end\"] = cls_index\n","        # else:\n","        start_char = df[\"answer_start\"].iloc[i]\n","        end_char = start_char + len(df[\"answer_text\"].iloc[i])\n","\n","        token_start_index = 0\n","        while sequence_ids[token_start_index] != 1:\n","          token_start_index += 1\n","\n","        token_end_index = len(example[\"input_ids\"]) - 1\n","        while sequence_ids[token_end_index] != 1:\n","          token_end_index -= 1\n","\n","        if not (example[\"offset_mapping\"][token_start_index][0] <= start_char and example[\"offset_mapping\"][token_end_index][1] >= end_char):\n","          example[\"answer_start\"] = cls_index\n","          example[\"answer_end\"] = cls_index\n","        else:\n","          while token_start_index < len(example[\"offset_mapping\"]) and example[\"offset_mapping\"][token_start_index][0] <= start_char:\n","            token_start_index += 1\n","          example[\"answer_start\"] = token_start_index - 1\n","          while example[\"offset_mapping\"][token_end_index][1] >= end_char:\n","            token_end_index -= 1\n","          example[\"answer_end\"] = token_end_index + 1\n","\n","        examples.append(example)\n"," \n","  # test\n","  else:\n","     for i in range(df.shape[0]):\n","      tokens_info = tokenize(tokenizer,df.iloc[i,:])\n","      for j in range(len(tokens_info[\"input_ids\"])):\n","        example = {}\n","        #example[\"id\"] = df[\"id\"].iloc[i]\n","        example[\"example_id\"] = df[\"id\"].iloc[i]\n","        example[\"context\"] = df[\"context\"].iloc[i]\n","        example[\"question\"] = df[\"question\"].iloc[i]\n","        example[\"input_ids\"] = tokens_info[\"input_ids\"][j]\n","        example[\"sequence_ids\"] = [0 if i == None else i for i in tokens_info.sequence_ids(j)]\n","        example[\"attention_mask\"] = tokens_info[\"attention_mask\"][j]\n","        example[\"offset_mapping\"] = tokens_info[\"offset_mapping\"][j]\n","        examples.append(example)\n","\n","  return examples"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V5dTItT_2pK_"},"source":["# Make Dataset"]},{"cell_type":"code","metadata":{"id":"HxYYRIJhm5e8"},"source":["class QA_Dataset(utils.data.Dataset):\n","  def __init__(self,examples):\n","    self.examples = examples\n","    # train\n","    if \"answer_start\" in self.examples[0].keys():\n","      self.is_train = 1\n","    # test\n","    else:\n","      self.is_train = 0\n","\n","  def __getitem__(self,idx):\n","    tensor_key = [\"input_ids\",\"attention_mask\",\"offset_mapping\"]\n","    item = {key:torch.tensor(value) for key,value in self.examples[idx].items() if key in tensor_key}\n","    item[\"id\"] = self.examples[idx][\"example_id\"]\n","    if self.is_train == 1:\n","      label = {\"answer_start\":torch.tensor(self.examples[idx][\"answer_start\"]),\n","               \"answer_end\":torch.tensor(self.examples[idx][\"answer_end\"])}\n","      return item,label\n","    else:\n","      #item[\"tokens\"] = self.examples[idx][\"tokens\"]\n","      item[\"context\"] = self.examples[idx][\"context\"]\n","      item[\"question\"] = self.examples[idx][\"question\"]\n","      item[\"sequence_ids\"] = self.examples[idx][\"sequence_ids\"]\n","      return item\n","\n","\n","  def __len__(self):\n","    return len(self.examples)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UldpytxJSe8M"},"source":["# Make DataLoader"]},{"cell_type":"code","metadata":{"id":"R36LmQcHSdrI"},"source":["def make_loader(*args):\n","  loaders = []\n","  if len(args) == 2:\n","    # train\n","    examples = make_examples(args[0])\n","    df_set = QA_Dataset(examples)\n","    loader = utils.data.DataLoader(df_set,batch_size=Config.train_batch_size,\n","                                   shuffle=True,pin_memory=True,drop_last=False)\n","    loaders.append(loader)\n","    # valid\n","    examples = make_examples(args[1])\n","    df_set = QA_Dataset(examples)\n","    loader = utils.data.DataLoader(df_set,batch_size=Config.valid_batch_size,\n","                                  pin_memory=True,sampler=utils.data.SequentialSampler(df_set),\n","                                  drop_last=False)\n","    loaders.append(loader)\n","  else:\n","    examples = make_examples(args[0])\n","    df_set = QA_Dataset(examples)\n","    loader = utils.data.DataLoader(df_set,batch_size=Config.valid_batch_size,pin_memory=True,sampler=utils.data.SequentialSampler(df_set),\n","                                  drop_last=False)\n","    loaders = loader\n","  \n","  return loaders\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tZ8OBA6D2sQ1"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"BmWD8zEW4i5g"},"source":["# Child Tuning"]},{"cell_type":"code","metadata":{"id":"GOlzesa0Dz37"},"source":["class MODEL(nn.Module):\n","  def __init__(self):\n","    super(MODEL, self).__init__()\n","    config = AutoConfig.from_pretrained(Config.model_name)\n","    self.xlm_roberta = AutoModel.from_pretrained(Config.model_name,config)\n","    # self.net = nn.Sequential(nn.Dropout(Config.hidden_dropout_prob),\n","    #                          nn.Linear(Config.hidden_size,Config.hidden_size),\n","    #                          nn.ReLU(),\n","    #                          )\n","    # self.net = nn.LSTM(Config.hidden_size,Config.hidden_size,num_layers=1,batch_first=True,\n","    #                    bidirectional=True)\n","    #self.fusion_head = FusionHead()\n","    # self.deform_head = DeformHead()\n","    # self.cnn_head = CNNHead()\n","    self.qa_outputs = nn.Linear(Config.hidden_size, 2)\n","                                  \n","    # self.start_label_weight = nn.Linear(Config.max_seq_len,Config.max_seq_len)\n","    # self.end_label_weight = nn.Linear(Config.max_seq_len,Config.max_seq_len)\n","    self.dropout = nn.Dropout(0.1)\n","    self._init_weights(self.qa_outputs)\n","      \n","  def _init_weights(self, module):\n","    if isinstance(module, nn.Linear):\n","        module.weight.data.normal_(mean=0.0, std=Config.initializer_range)\n","        if module.bias is not None:\n","            module.bias.data.zero_()\n","\n","  def forward(\n","        self, \n","        input\n","    ):\n","        output = self.xlm_roberta(\n","            **input,output_hidden_states=True\n","        )\n","        \n","        output = output.last_hidden_state # B*L*H\n","        \n","        #last_8_layers = torch.cat([output[i] for i in [9,14,19,23]],dim=-1) # B*L*4H\n","        #last_8_layers = self.dropout(last_8_layers)\n","        #cls_8_layers = last_8_layers[:,:]\n","        # cls_8_layers = cls_8_layers.repeat(1,Config.max_seq_len,1)\n","        #last_8_layers = self.dropout(last_8_layers)\n","\n","        #fusion_output = self.fusion_head(last_8_layers)\n","        # cnn_output = self.cnn_head(last_8_layers)\n","        # deform_cnn = self.deform_head(cnn_output)\n","        #fusion_output = torch.cat([last_8_layers,fusion_output],dim=-1)\n","\n","        #sequence_output = self.dropout()\n","        # sequence_output,_ = self.net(sequence_output)\n","\n","        #sequence_output = self.dropout(sequence_output)\n","        #fusion_output = self.dropout(fusion_output)\n","        qa_logits = self.qa_outputs(output)\n","        \n","        start_logits, end_logits = qa_logits.split(1, dim=-1)\n","        start_logits = start_logits.squeeze(-1)\n","        end_logits = end_logits.squeeze(-1)\n","\n","        #del fusion_output,cls_8_layers,last_8_layers,output\n","        #torch.cuda.empty_cache()\n","    \n","        return start_logits, end_logits\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HJC2vwud2ujq"},"source":["# class MODEL(nn.Module):\n","#   def __init__(self):\n","#     super(MODEL, self).__init__()\n","#     config = AutoConfig.from_pretrained(Config.model_name)\n","#     self.roberta = AutoModel.from_pretrained(Config.model_name,config)\n","#     # self.net = nn.Sequential(nn.Dropout(Config.hidden_dropout_prob),\n","#     #                          nn.Linear(Config.hidden_size,Config.hidden_size),\n","#     #                          nn.ReLU(),\n","#     #                          )\n","#     # self.net = nn.LSTM(Config.hidden_size,Config.hidden_size,num_layers=1,batch_first=True,\n","#     #                    bidirectional=True)\n","#     self.fusion_head = FusionHead()\n","#     # self.deform_head = DeformHead()\n","#     # self.cnn_head = CNNHead()\n","#     self.qa_outputs = nn.Linear(Config.hidden_size*8, 2)\n","                                  \n","#     # self.start_label_weight = nn.Linear(Config.max_seq_len,Config.max_seq_len)\n","#     # self.end_label_weight = nn.Linear(Config.max_seq_len,Config.max_seq_len)\n","#     self.dropout = nn.Dropout(0.1)\n","#     self._init_weights(self.qa_outputs)\n","      \n","#   def _init_weights(self, module):\n","#     if isinstance(module, nn.Linear):\n","#         module.weight.data.normal_(mean=0.0, std=Config.initializer_range)\n","#         if module.bias is not None:\n","#             module.bias.data.zero_()\n","\n","#   def forward(\n","#         self, \n","#         input\n","#     ):\n","#         output = self.roberta(\n","#             **input,output_hidden_states=True\n","#         )\n","        \n","#         output = output.hidden_states # B*L*H\n","        \n","#         last_8_layers = torch.cat([output[i] for i in [9,14,19,23]],dim=-1) # B*L*4H\n","#         #last_8_layers = self.dropout(last_8_layers)\n","#         #cls_8_layers = last_8_layers[:,:]\n","#         # cls_8_layers = cls_8_layers.repeat(1,Config.max_seq_len,1)\n","#         last_8_layers = self.dropout(last_8_layers)\n","\n","#         fusion_output = self.fusion_head(last_8_layers)\n","#         # cnn_output = self.cnn_head(last_8_layers)\n","#         # deform_cnn = self.deform_head(cnn_output)\n","#         fusion_output = torch.cat([last_8_layers,fusion_output],dim=-1)\n","\n","#         #sequence_output = self.dropout()\n","#         # sequence_output,_ = self.net(sequence_output)\n","\n","#         #sequence_output = self.dropout(sequence_output)\n","#         #fusion_output = self.dropout(fusion_output)\n","#         qa_logits = self.qa_outputs(fusion_output)\n","        \n","#         start_logits, end_logits = qa_logits.split(1, dim=-1)\n","#         start_logits = start_logits.squeeze(-1)\n","#         end_logits = end_logits.squeeze(-1)\n","\n","#         #del fusion_output,cls_8_layers,last_8_layers,output\n","#         #torch.cuda.empty_cache()\n","    \n","#         return start_logits, end_logits\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uFFwqZRtoLT5"},"source":["Head"]},{"cell_type":"code","metadata":{"id":"Y8wZul02oN-1"},"source":["class FusionHead(nn.Module):\n","  def __init__(self):\n","    super(FusionHead,self).__init__()\n","    self.q = nn.Linear(Config.hidden_size*4,512)\n","    self.v = nn.Linear(512,1)\n","    self._init_weights(self.q)\n","    self._init_weights(self.v)\n","\n","  \n","  def forward(self,seq):\n","    # seq : (B,L,H*4)\n","    score = self.v(nn.functional.tanh(self.q(seq))) # B*L*1\n","    score = nn.functional.softmax(score,dim=1) \n","    seq =  score*seq\n","    return seq\n","\n","  def _init_weights(self, module):\n","    if isinstance(module, nn.Linear):\n","      module.weight.data.normal_(mean=0.0, std=Config.initializer_range)\n","      if module.bias is not None:\n","          module.bias.data.zero_()\n","\n","class DeformHead(nn.Module):\n","  def __init__(self):\n","    super(DeformHead,self).__init__()\n","    self.q = nn.Linear(Config.hidden_size*2,Config.hidden_size*4)\n","    self.k = nn.Linear(Config.hidden_size*2,512)\n","    self.v = nn.Linear(512,1)\n","  \n","  def forward(self,seq):\n","    # seq : (B,L,2H)\n","    score = self.v(nn.functional.tanh(self.k(seq))) # B*L*4H\n","    score = nn.functional.softmax(score,dim=1)  \n","    seq =  score*nn.functional.relu(self.q(seq))\n","    return seq\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aen-Cg3zVTLV"},"source":["class CNNHead(nn.Module):\n","  def __init__(self):\n","    super(CNNHead,self).__init__()\n","    # B*L*4H\n","    self.conv1 = nn.Conv1d(Config.hidden_size*4,Config.hidden_size,1,1,0) # B*L*1024\n","    self.conv2 = nn.Conv1d(Config.hidden_size*4,Config.hidden_size,3,1,1) # B*L*1024\n","\n","  def forward(self,seq):\n","    # seq : (B,L,H*4)\n","    seq = torch.permute(seq,(0,2,1))\n","    x1 = nn.functional.relu(self.conv1(seq))\n","    x2 = nn.functional.relu(self.conv2(seq))\n","\n","    x1 = torch.permute(x1,(0,2,1))\n","    x2 = torch.permute(x2,(0,2,1))\n","    x = torch.cat((x1,x2),dim=-1)\n","    del x1,x2\n","    return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pq-g996fbHPb"},"source":["# Training/Testing\n"]},{"cell_type":"markdown","metadata":{"id":"KzRSd1b6ZQsY"},"source":["loss"]},{"cell_type":"code","metadata":{"id":"lmxHsZXQZSKk"},"source":["def qa_loss(start_pred,end_pred,start_ans,end_ans):\n","  start_loss = nn.CrossEntropyLoss()(start_pred,start_ans)\n","  end_loss = nn.CrossEntropyLoss()(end_pred,end_ans)\n","  loss = (start_loss+end_loss)/2\n","  del start_loss,end_loss\n","  torch.cuda.empty_cache()\n","  return loss\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NEvuiMeAr0z6"},"source":["Scheduler"]},{"cell_type":"code","metadata":{"id":"bQ-F6GOKbGLi"},"source":["def qa_scheduler(optimizer,warm_steps,num_training_steps):\n","  scler = transformers.get_cosine_schedule_with_warmup(optimizer,\n","                                                       num_warmup_steps=warm_steps,\n","                                                       num_training_steps=num_training_steps,\n","                                                       )\n","\n","  return scler\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ebFplmsg0Ujo"},"source":["Optimizer"]},{"cell_type":"code","metadata":{"id":"Mhq8mGh4IfzL"},"source":["def get_optimizer_grouped_parameters(model):\n","    parameters = list(model.named_parameters())\n","\n","    bert_parameters = parameters[:389]\n","    #head_parameters = parameters[391:395]\n","    net_parameters = parameters[391:]\n","\n","    #head_default_parameters = [param for name,param in head_parameters]\n","    net_default_parameters = [param for name,param in net_parameters]\n","\n","    down_lr = Config.down_lr\n","    parameters = []\n","\n","    bert_increase_lr = [(1/0.95)**i for i in range(24)]#np.linspace(1,5,24)\n","    for name,param in bert_parameters:\n","      temp = name.split(\".\")\n","      if len(temp)>=4 and str.isdigit(temp[3]):\n","        parameters.append({\"params\":param,\n","                           \"weight_decay\":Config.weight_decay if \"bias\" not in name else 0.0,\n","                           \"lr\":Config.learning_rate*bert_increase_lr[int(temp[3])]}\n","                          )\n","      else:\n","        parameters.append({\"params\":param,\n","                           \"weight_decay\":Config.weight_decay if \"bias\" not in name else 0.0,\n","                           \"lr\":Config.learning_rate}\n","                          )\n","    \n","    if Config.down_specific:\n","      # for name,param in head_parameters:\n","      #   parameters.append({\"params\":param,\n","      #                      \"weight_decay\":Config.weight_decay if \"bias\" not in name else 0.0,\n","      #                      \"lr\":Config.down_lr}\n","      #                     )\n","      for name,param in net_parameters:\n","        parameters.append({\"params\":param,\n","                           \"weight_decay\":Config.weight_decay if \"bias\" not in name else 0.0,\n","                           \"lr\":Config.down_lr}\n","                          )\n","    else:\n","      parameters.append({\"params\":head_default_parameters})\n","      parameters.append({\"params\":net_default_parameters})\n","    \n","    return parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QJQoI64M0UDc"},"source":["execfile(\"/content/drive/MyDrive/Kaggle/Hindi/models/childtuning.py\")\n","\n","def qa_optimizer(model):\n","  no_decay = [\"bias\", \"LayerNorm.weight\"]\n","  opt_params = [\n","      {\n","          \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","          \"weight_decay\": Config.weight_decay,\n","      },\n","      {\n","          \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","          \"weight_decay\": 0.0,\n","      },\n","  ]\n","  #opt_params = get_optimizer_grouped_parameters(model)\n","  # optimizer = transformers.AdamW(opt_params,\n","  #                               lr=Config.learning_rate,\n","  #                               eps=Config.epsilon,\n","  #                               correct_bias=Config.correct_bias)\n","  \n","  optimizer = transformers.AdamW(opt_params,lr=Config.learning_rate,eps=Config.epsilon,correct_bias=Config.correct_bias)\n","  \n","  return optimizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C64n3yXZr5kL"},"source":["Training"]},{"cell_type":"code","metadata":{"id":"heDp2UJF9Bug"},"source":["class Metric():\n","  def __init__(self,name):\n","    self.min = 1\n","    self.max = 0\n","    self.loss = 0\n","    self.sum = 0\n","    self.count = 0\n","    self.ave = 0\n","    self.index = 0\n","    self.writer = SummaryWriter(name)\n","    self.name = name\n","\n","  def step(self,loss):\n","    self.sum += loss\n","    self.count += 1\n","    self.index += 1\n","    self.ave = self.sum/self.count\n","    self.max = max(self.max,loss)\n","    self.min = min(self.min,loss)\n","    self.loss = loss\n","\n","  def reset(self):\n","    self.loss = 0\n","    self.sum = 0\n","    self.count = 0\n","    self.ave = 0\n","\n","  def log(self,tag):\n","    self.writer.add_scalar(tag,self.ave,self.index)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bf9v1p2eZ3R1"},"source":["class QA_Trainer():\n","  def __init__(self,model,optimizer,scler,train_loader,df_valid,valid_loader,valid_examples):\n","    self.model = model\n","    self.optimizer = optimizer\n","    self.scler = scler\n","    self.train_loader = train_loader\n","    self.df_valid = df_valid\n","    self.valid_loader = valid_loader\n","    self.valid_examples = valid_examples\n","    \n","\n","  def fit(self):\n","    epoch = 0\n","    patience = 0\n","    metric = Metric(Config.train_loss_path)\n","    \n","    while epoch < Config.n_epochs:\n","      self.model.train()\n","      for step,(item,label) in enumerate(self.train_loader):\n","        input = {key:item[key].to(Config.device) for key in item.keys() if key in [\"input_ids\",\"attention_mask\"]}\n","        start_ans,end_ans = label[\"answer_start\"].to(Config.device),label[\"answer_end\"].to(Config.device)\n","\n","        start_pred,end_pred = self.model(input)\n","        loss = qa_loss(start_pred,end_pred,start_ans,end_ans)\n","        loss = loss/Config.acc_gradient_steps\n","\n","        if Config.fp16:\n","          with amp.scale_loss(loss,self.optimizer) as scaled_loss:\n","            scaled_loss.backward()\n","        else:\n","          loss.backward()\n","\n","        metric.step(loss.item())\n","\n","        if step%Config.acc_gradient_steps == 0 or step == len(self.train_loader) - 1:\n","          self.optimizer.step()\n","          self.scler.step()\n","          self.optimizer.zero_grad()\n","\n","        if step % Config.log_steps == 0:\n","          print(\"Epoch: {}\\t||\\tStep: {}/{}\\t||\\tAverage loss: {}\\t||Max loss: {}\\t||\\t Min loss: {}\".format(epoch,step,len(self.train_loader),metric.ave,metric.max,metric.min))\n","          #metric.log(\"model_128_2/train_loss\")\n","          metric.reset()\n","        # if step % Config.valid_intervals == 0:\n","        #   loss = QA_Tester.evaluate(self.model,self.valid_loader)\n","        #   acc = validation(self.model,self.df_valid,self.valid_loader,self.valid_examples)\n","        #   if acc <= Config.best_acc:\n","        #     if epoch > 0:\n","        #       patience += 1\n","        #   else:\n","        #     Config.best_acc = acc\n","        #     patience = 0\n","        #   if patience == Config.patience:\n","        #     print(\"Early stopping has reached!\")\n","        #     del item,label,loss,start_pred,end_pred,input,start_ans,end_ans\n","        #     torch.cuda.empty_cache()\n","        #     return self.model\n","\n","        del item,label,loss,start_pred,end_pred,input,start_ans,end_ans\n","        torch.cuda.empty_cache()\n","\n","      #loss = QA_Tester.evaluate(self.model,self.valid_loader)\n","      acc = validation(self.model,self.df_valid,self.valid_loader,self.valid_examples)\n","      if acc <= Config.best_acc:\n","        patience += 1\n","      else:\n","        Config.best_acc = acc\n","        patience = 0\n","      if patience == Config.patience:\n","        print(\"Early stopping has reached!\")\n","        break\n","\n","      epoch += 1\n","    \n","    return self.model\n","\n","  def evaluate(self):\n","      QA_Tester.evaluate(self.model,self.valid_loader)\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DwadqMXbvQ2"},"source":["class QA_Trainer_HT():\n","  def __init__(self,model,optimizer,scler,train_loader,df_valid,valid_loader,valid_examples,params):\n","    self.model = model\n","    self.optimizer = optimizer\n","    self.scler = scler\n","    self.train_loader = train_loader\n","    self.df_valid = df_valid\n","    self.valid_loader = valid_loader\n","    self.valid_examples = valid_examples\n","    self.params = params\n","\n","  def fit(self):\n","    epoch = 0\n","    patience = 0\n","    metric = Metric(Config.train_loss_path)\n","    \n","    while epoch < self.params[\"n_epochs\"]:\n","      self.model.train()\n","      for step,(item,label) in enumerate(self.train_loader):\n","        input = {key:item[key].to(Config.device) for key in item.keys() if key in [\"input_ids\",\"attention_mask\"]}\n","        start_ans,end_ans = label[\"answer_start\"].to(Config.device),label[\"answer_end\"].to(Config.device)\n","\n","        start_pred,end_pred = self.model(input)\n","        loss = qa_loss(start_pred,end_pred,start_ans,end_ans)\n","\n","        if Config.fp16:\n","          with amp.scale_loss(loss,self.optimizer) as scaled_loss:\n","            scaled_loss.backward()\n","        else:\n","          loss.backward()\n","\n","        metric.step(loss.item())\n","\n","        self.optimizer.step()\n","        self.scler.step()\n","        self.optimizer.zero_grad()\n","\n","        del item,label,loss,start_pred,end_pred,input,start_ans,end_ans\n","        torch.cuda.empty_cache()\n","\n","        # if step%Config.log_steps:\n","        #   print(\"-\"*50)\n","        #   print(\"loss: {}\".format(metric.ave))\n","          \n","      #loss = QA_Tester.evaluate(self.model,self.valid_loader)\n","      acc = validation(self.model,self.df_valid,self.valid_loader,self.valid_examples)\n","\n","      epoch += 1\n","\n","    self.exit()\n","    return acc\n","\n","  def evaluate(self):\n","      QA_Tester.evaluate(self.model,self.valid_loader)\n","\n","  def exit(self):\n","    try: \n","      del self.optimizer,self.scler,self.model\n","    except:\n","      pass\n","    torch.cuda.empty_cache()\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e2pqzHLisBs0"},"source":["Testing"]},{"cell_type":"code","metadata":{"id":"NhL3OPRGsCXn"},"source":["\n","class QA_Tester():\n","  def evaluate(model,valid_loader):\n","    model.eval()\n","    losses = []\n","    \n","    with torch.no_grad():\n","      for item,label in valid_loader:\n","        input = {key:item[key].to(Config.device) for key in item.keys() if key in [\"input_ids\",\"attention_mask\"]}\n","        start_ans,end_ans = label[\"answer_start\"].to(Config.device),label[\"answer_end\"].to(Config.device)\n","\n","        start_pred,end_pred = model(input)\n","        loss = qa_loss(start_pred,end_pred,start_ans,end_ans)\n","        losses.append(loss.item())\n","\n","        del input,item,label,start_ans,end_ans,start_pred,end_pred,loss\n","        torch.cuda.empty_cache()\n","\n","    ave = np.mean(losses)\n","    print(\"Validation Loss -------------->: {}\".format(ave))\n","    #if ave < Config.best_loss:\n","      #print(\"best model has been stored!\")\n","      #torch.save(model.state_dict(),re.sub(r\"fold_[0-9]\",str(Config.fold),Config.checkpoint))\n","    model.train()\n","    return ave\n","\n","  def predict(model,test_loader):\n","    pass\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tzFKyE2DY-94"},"source":["# Hyperparameters Tuning Class"]},{"cell_type":"code","metadata":{"id":"Cl6694H7fvqc"},"source":["#!pip install optuna"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0H_Wh12Y-P4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SckCa-xcTUnB"},"source":["# Validation"]},{"cell_type":"code","metadata":{"id":"Gp9pbel0TZaJ"},"source":["execfile(\"/content/drive/MyDrive/Kaggle/Hindi/models/validation.py\")\n","\n","def validation(model,df_valid,valid_loader,valid_examples,if_save=True):\n","  model.eval()\n","  def getPredictions():\n","    start_logits = []\n","    end_logits = []\n","    for item,label in valid_loader:\n","        with torch.no_grad():\n","            input = {key:item[key].to(Config.device) for key in item.keys() if key in [\"input_ids\",\"attention_mask\"]}\n","            \n","            outputs_start, outputs_end = model(input)\n","            start_logits.append(outputs_start.cpu().numpy().tolist())\n","            end_logits.append(outputs_end.cpu().numpy().tolist())\n","            del outputs_start, outputs_end\n","    return np.vstack(start_logits), np.vstack(end_logits)\n","  model.train()\n","  start_logits, end_logits = getPredictions()\n","  acc,df_res = computeJaccard(df_valid,valid_examples,start_logits, end_logits)\n","  print(\"Fold: {}\\t||\\tValidation Jaccard Score: -------------->: {}\".format(Config.fold,acc))\n","\n","  if acc > Config.best_acc:\n","      if if_save:\n","        print(\"best model has been stored!\")\n","        torch.save(model.state_dict(),re.sub(r\"fold_[0-9]\",\"fold_\"+str(Config.fold),Config.checkpoint))\n","  return acc\n","\n","def prediction(model,df_valid,valid_loader,valid_examples):\n","  df_valid[\"answer_text\"] = ['text']*df_valid.shape[0]\n","  def getPredictions():\n","    start_logits = []\n","    end_logits = []\n","    for item in valid_loader:\n","        with torch.no_grad():\n","            input = {key:item[key].to(Config.device) for key in item.keys() if key in [\"input_ids\",\"attention_mask\"]}\n","            #print(input[\"input_ids\"][0])\n","            outputs_start, outputs_end = model(input)\n","            start_logits.append(outputs_start.cpu().numpy().tolist())\n","            end_logits.append(outputs_end.cpu().numpy().tolist())\n","            del outputs_start, outputs_end\n","    return np.vstack(start_logits), np.vstack(end_logits)\n","\n","  start_logits, end_logits = getPredictions()\n","  acc,df_res = computeJaccard(df_valid,valid_examples,start_logits, end_logits)\n","  print(df_res)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Dh40v5NtBxb"},"source":["# Run"]},{"cell_type":"code","metadata":{"id":"mOGwdRi--Haw"},"source":["def checkpoint_call(path=None,is_checkpoint=False,cuda=True):\n","  if is_checkpoint:\n","    model = MODEL()\n","    state_dict = torch.load(path)\n","    for n,p in model.named_parameters():\n","      if n not in state_dict.keys():\n","        state_dict[n] = p\n","    \n","    drop_list = []\n","    for n,p in state_dict.items():\n","      if n not in model.state_dict().keys():\n","        drop_list.append(n)\n","    \n","    for i in drop_list:\n","      state_dict.pop(i)\n","\n","    model.load_state_dict(state_dict)\n","    #model._init_weights(model.qa_outputs)\n","  else:\n","    model = MODEL()\n","\n","  return model.to(Config.device) if cuda == True else model.cpu()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BIo-6KfItBNT"},"source":["def model_training(model,train_loader,df_valid,valid_loader,valid_examples):\n","  fix_all_seeds(Config.seed)\n","  optimizer = qa_optimizer(model)\n","  num_training_steps = len(train_loader)/Config.acc_gradient_steps*Config.n_epochs\n","  warm_steps = int(num_training_steps*Config.warm_frac)\n","  if Config.fp16:\n","    model,optimizer = amp.initialize(model,optimizer,opt_level=Config.fp16_opt_level)\n","  scler = qa_scheduler(optimizer,warm_steps,num_training_steps)\n","  trainer = QA_Trainer(model,optimizer,scler,train_loader,df_valid,valid_loader,valid_examples)\n","  model = trainer.fit()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ev5hq3yHsq4"},"source":["def model_training_fold(model,train_loader,df_valid,valid_loader,valid_examples):\n","  fix_all_seeds(Config.seed)\n","  optimizer = qa_optimizer(model)\n","  num_training_steps = len(train_loader)/Config.acc_gradient_steps*Config.n_epochs\n","  warm_steps = int(num_training_steps*Config.warm_frac)\n","  if Config.fp16:\n","    model,optimizer = amp.initialize(model,optimizer,opt_level=Config.fp16_opt_level)\n","  scler = qa_scheduler(optimizer,warm_steps,num_training_steps)\n","  trainer = QA_Trainer(model,optimizer,scler,train_loader,df_valid,valid_loader,valid_examples)\n","  model = trainer.fit()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d7tyO0ZWdEwF"},"source":["def model_training_fold_HT(model,train_loader,df_valid,valid_loader,valid_examples,params):\n","  fix_all_seeds(params[\"seed\"])\n","  optimizer = qa_optimizer(model)\n","  num_training_steps = len(train_loader)*Config.n_epochs\n","  warm_steps = int(num_training_steps*Config.warm_frac)\n","  if Config.fp16:\n","    model,optimizer = amp.initialize(model,optimizer,opt_level=Config.fp16_opt_level)\n","  scler = qa_scheduler(optimizer,warm_steps,num_training_steps)\n","  trainer = QA_Trainer_HT(model,optimizer,scler,train_loader,df_valid,valid_loader,valid_examples,params)\n","  acc = trainer.fit()\n","\n","  del model,scler,optimizer,trainer\n","  torch.cuda.empty_cache()\n","  return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tNM7C91oNbEi"},"source":["from sklearn.model_selection import StratifiedKFold\n","def make_fold():\n","  train = pd.read_csv('/content/drive/MyDrive/Kaggle/Hindi/input/cleaned_train.csv')\n","  external_mlqa = pd.read_csv('/content/drive/MyDrive/Kaggle/Hindi/input/mlqa_hindi.csv')\n","  external_xquad = pd.read_csv('/content/drive/MyDrive/Kaggle/Hindi/input/xquad.csv')\n","  tamil_xquad = pd.read_csv('/content/drive/MyDrive/Kaggle/Hindi/input/squad_translated_tamil.csv')\n","  tamil_xquad[\"language\"] = [\"tamil\"]*tamil_xquad.shape[0]\n","  external_train = pd.concat([external_mlqa, external_xquad,tamil_xquad],ignore_index=True).reset_index(drop=True)\n","\n","  def create_folds(data, num_splits):\n","      data[\"kfold\"] = -1\n","      kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=Config.seed)\n","      for f, (t_, v_) in enumerate(kf.split(X=data, y=data['language'])):\n","          data.loc[v_, 'kfold'] = f\n","      return data\n","\n","  train = create_folds(train, num_splits=5)\n","  external_train[\"kfold\"] = -1\n","  train = pd.concat([train, external_train],ignore_index=True).reset_index(drop=True)\n","  train['id'] = list(np.arange(1, len(train)+1))\n","  train.to_csv(\"input.csv\")\n","  return train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jjln7WsZFQO8"},"source":["def run(fold):\n","  Config.fold = fold\n","  train = pd.read_csv(\"input.csv\")\n","  valid = train.loc[train[\"kfold\"]==fold,:]\n","  train = train.loc[train[\"kfold\"]!=fold,:]\n","  train = text_preprocess(train)\n","  valid = text_preprocess(valid)\n","  print(\"Making data...\")\n","  train_loader,valid_loader = make_loader(train,valid)\n","  valid_examples = make_examples(valid)\n","\n","  torch.cuda.empty_cache()\n","\n","\n","  model = checkpoint_call(\"/content/drive/MyDrive/Kaggle/Hindi/checkpoints/simple_adding_model/simple_adding_model.bin\",is_checkpoint=False)\n","  model_training_fold(model,train_loader,valid,valid_loader,valid_examples)\n","\n","  del model,train_loader,valid_loader,train,valid,valid_examples\n","  torch.cuda.empty_cache()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WEHuTZVQf6K1"},"source":["# Hyperparameter Tuning\n"]},{"cell_type":"code","metadata":{"id":"qttXtL5-f52A"},"source":["# train = pd.read_csv(base+\"input/train.csv\").sample(frac=0.1,random_state=3407)\n","# searcher = params_optim(train,100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rv2ngGfsgnGk"},"source":["# %pdb off\n","# best_params = searcher.search()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J2EBhdcAf3yC"},"source":["# 5 Fold"]},{"cell_type":"code","metadata":{"id":"Q1asTOBt_FaK"},"source":["# train = make_fold()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Yjnmk-DeEux"},"source":["%pdb off\n","for fold in range(0,5):\n","  Config.best_loss = 1\n","  Config.best_acc = 0\n","  run(fold)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aNik2RQf0m59"},"source":["Pure Validation"]},{"cell_type":"code","metadata":{"id":"JAWAjHvt0RCV"},"source":["# %pdb off\n","# execfile(\"/content/drive/MyDrive/Kaggle/Hindi/models/validation.py\")\n","\n","for i in range(0,5):\n","  train = pd.read_csv(base+\"/input/train.csv\")\n","  #valid = train[train[\"language\"]==\"hindi\"]\n","  valid = text_preprocess(train)\n","  valid_loader = make_loader(valid)\n","  valid_examples = make_examples(valid)\n","\n","  model = checkpoint_call(\"/content/output/fold_{}.bin\".format(i),is_checkpoint=True)\n","  acc = validation(model,valid,valid_loader,valid_examples,if_save=False)\n","\n","  del model\n","  torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vMA6XNgD-GUg"},"source":["ds # train = pd.read_csv(base+\"/input/final_corpus.csv\")\n","# train[[\"context\",\"question\",\"answer_text\"]].duplicated().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jhSFGpviPdr-"},"source":["# Local Test"]},{"cell_type":"code","metadata":{"id":"_D1BO3RfSDAs"},"source":["!kaggle datasets download -d charonwangg/deep-wiki-v2\n","!kaggle datasets download -d charonwangg/overfitting-5-fold-128\n","!kaggle datasets download -d kishalmandal/5foldsroberta\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OlsdiNfQPdVl"},"source":["from tqdm import tqdm\n","def local_test(model,df_valid,valid_loader,valid_examples):\n","  def getPredictions(model):\n","    start_logits = []\n","    end_logits = []\n","    model.eval()\n","    for item,label in valid_loader:\n","        with torch.no_grad():\n","            input = {key:item[key].to(Config.device) for key in item.keys() if key in [\"input_ids\",\"attention_mask\"]}\n","            \n","            outputs_start, outputs_end = model(input)\n","            start_logits.append(outputs_start.cpu().numpy().tolist())\n","            end_logits.append(outputs_end.cpu().numpy().tolist())\n","            del outputs_start, outputs_end\n","    return np.vstack(start_logits), np.vstack(end_logits)\n","\n","    start_logits_, end_logits_ = getPredictions(model)\n","\n","\n","  #acc,df_res = computeJaccard(df_valid,valid_examples,start_logits, end_logits)\n","  #print(\"Fold: {}\\t||\\tValidation Jaccard Score: -------------->: {}\".format(Config.fold,acc))\n","\n","  return start_logits_, end_logits_\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSwWH_ZitL__"},"source":["train = pd.read_csv(base+\"/input/train.csv\")\n","#valid = train[train[\"language\"]==\"hindi\"]\n","valid = text_preprocess(train)\n","valid_loader = make_loader(valid)\n","valid_examples = make_examples(valid)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SLlfDUL5rzQl"},"source":["paths = []\n","\n","weight = np.exp([0.7189407410715103,0.7009346291550066,0.7423611924357781,0.7452209457707667,0.7328501876639222\\\n","          ,0.7409769800815581,0.7214328330609091,0.7293411617805697,0.8074233752981514,0.7191098087529867,\\\n","          0.7982931852209235,0.7737983627682914,0.7776064350570635,0.7843168579166172,0.7358640175404093,\\\n","                 0.7166820931307615])\n","\n","\n","model = checkpoint_call(\"/content/drive/MyDrive/Kaggle/Hindi/checkpoints/simple_adding_model/simple_adding_model.bin\",\n","                              is_checkpoint=True)\n","start_logits_, end_logits_ = local_test(model,valid,valid_loader,valid_examples)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"btTPwKeNRDJ-"},"source":["train = pd.read_csv(base+\"/input/train.csv\")\n","#valid = train[train[\"language\"]==\"hindi\"]\n","valid = text_preprocess(train)\n","valid_loader = make_loader(valid)\n","valid_examples = make_examples(valid)\n","\n","weight = np.exp([0.7189407410715103,0.7009346291550066,0.7423611924357781,0.7452209457707667,0.7328501876639222\\\n","          ,0.7409769800815581,0.7214328330609091,0.7293411617805697,0.8074233752981514,0.7191098087529867,\\\n","          0.7982931852209235,0.7737983627682914,0.7776064350570635,0.7843168579166172,0.7358640175404093,\\\n","                 0.7166820931307615])\n","\n","models = []\n","models.append(checkpoint_call(\"/content/output/fold_{}.bin\",\n","                              is_checkpoint=True))\n","models.append(checkpoint_call(\"/content/output/fold_{}.bin\",\n","                              is_checkpoint=True))\n","models.append(checkpoint_call(\"/content/output/fold_{}.bin\",\n","                              is_checkpoint=True))\n","models.append(checkpoint_call(\"/content/output/fold_{}.bin\",\n","                              is_checkpoint=True))\n","models.append(checkpoint_call(\"/content/output/fold_{}.bin\",\n","                              is_checkpoint=True))\n","models.append(checkpoint_call(\"/content/drive/MyDrive/Kaggle/Hindi/checkpoints/simple_adding_model/simple_adding_model.bin\",\n","                              is_checkpoint=True))\n","models.append(checkpoint_call(\"/content/output/fold_{}.bin\",\n","                              is_checkpoint=True))\n","models.append(checkpoint_call(\"/content/output/fold_{}.bin\",\n","                              is_checkpoint=True))\n","models.append(checkpoint_call(\"/content/output/fold_{}.bin\",\n","                              is_checkpoint=True))\n","acc = local_test(models,weight,valid,valid_loader,valid_examples)\n","\n","torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WRYP0Ygn0R3B"},"source":["# Non-necessary"]},{"cell_type":"code","metadata":{"id":"v87YgKgOykXj"},"source":["# %pdb off\n","# #train_data,valid_data = train_test_split(train,train_size=0.9,stratify=train[\"language\"])\n","# train_loader,valid_loader = make_loader(train,valid)\n","# del train,valid\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ciAVkO5buRKD"},"source":["# try:\n","#   del model\n","# except:\n","#   pass\n","\n","# try:\n","#   del models\n","# except:\n","#   pass\n","\n","# torch.cuda.empty_cache()\n","\n","# model = checkpoint_call(\"/content/drive/MyDrive/Kaggle/Hindi/checkpoints/simple_adding_model/simple_adding_model.bin\",is_checkpoint=True)\n","# model_training(model,train_loader,valid_loader)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IlsJxlHQvbm0"},"source":["# try:\n","#   del model\n","# except:\n","#   pass\n","\n","# try:\n","#   del models\n","# except:\n","#   pass\n","\n","# torch.cuda.empty_cache()\n","# models = xxl_checkpoint_call(\"/content/output/checkpoint-fold-0/pytorch_model.bin\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V5S9m-zy3gvY"},"source":["#model_training(models,train_loader,valid_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aXMUgG3Exzzw"},"source":["# QA_Tester.evaluate(model,valid_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"izGq-M-pnX29"},"source":["# QA_Tester.evaluate(model,valid_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ql23G3Y8QTNW"},"source":["# torch.save(model.state_dict(),\"drive/MyDrive/checkpoint1.bin\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RT0URGBQR4uK"},"source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","\n","\n","# Then move kaggle.json into the folder where the API expects to find it.\n","!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9Frgsrylflj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636986156817,"user_tz":300,"elapsed":101400,"user":{"displayName":"Xinyue Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicuncDU8Icen2R8DV3Zp8YKvgAaXknWiF6RfZq=s64","userId":"06186608546937139658"}},"outputId":"fb2079d2-26ea-4f28-e363-2948b478123d"},"source":["!kaggle datasets create -p \"/content/output\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting upload for file fold_1.bin\n","Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n","100% 2.09G/2.09G [00:19<00:00, 117MB/s]\n","Upload successful: fold_1.bin (2GB)\n","Starting upload for file fold_0.bin\n","100% 2.09G/2.09G [00:19<00:00, 116MB/s]\n","Upload successful: fold_0.bin (2GB)\n","Starting upload for file fold_2.bin\n","100% 2.09G/2.09G [00:19<00:00, 115MB/s]\n","Upload successful: fold_2.bin (2GB)\n","Starting upload for file fold_3.bin\n","100% 2.09G/2.09G [00:19<00:00, 114MB/s]\n","Upload successful: fold_3.bin (2GB)\n","Starting upload for file fold_4.bin\n","100% 2.09G/2.09G [00:19<00:00, 117MB/s]\n","Upload successful: fold_4.bin (2GB)\n","Your private Dataset is being created. Please check progress at https://www.kaggle.com/charonwangg/Deep-Wiki-v2\n"]}]},{"cell_type":"code","metadata":{"id":"WIyCmpRfloKF"},"source":[""],"execution_count":null,"outputs":[]}]}